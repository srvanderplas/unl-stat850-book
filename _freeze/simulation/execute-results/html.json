{
  "hash": "75a7c7eb46687e8448ecfe35e682f9db",
  "result": {
    "markdown": "---\nbibliography: references.bib\n---\n\n\n# Simulation and Reproducibility {#simulation}\n\n## Module Objectives {#module12-objectives .unnumbered}\n\n-   Program a simulation for a specific task, process, or model\n-   Understand the limitaitons of pseudorandom number generation\n\nSimulation is an extremely important part of computational statistics. Bayesian statistics, in particular, relies on Markov Chain Monte Carlo (MCMC) to get results from even the most basic of models. In this module, we're going to touch on a few foundational pieces of simulation in computing, and you will get more exposure to simulation-based methods in other courses down the line.\n\n## Pseudorandom Number Generation\n\nComputers are almost entirely deterministic, which makes it very difficult to come up with \"random\" numbers. In addition to the deterministic nature of computing, it's also somewhat important to be able to run the same code and get the same results every time, which isn't possible if you rely on truly random numbers.\n\nHistorically, **pseudorandom** numbers were generated using linear congruential generators (LCGs) [@wikipediacontributorsLinearCongruentialGenerator2022]. These algorithms aren't typically used anymore, but they provide a good demonstration of how one might go about generating numbers that seem \"random\" but are actually deterministic. LCGs use modular arithmetic: $$X_{n+1} = (aX_n + c) \\mod m$$ where $X_0$ is the start value (the seed), $a$ is the multiplier, $c$ is the increment, and $m$ is the modulus. When using a LCG, the user generally specifies only the seed.\n\n![LCGs generate numbers which at first appear random, but once sufficiently many numbers have been generated, it is clear that there is some structure in the data. (Image from Wikimedia)](https://upload.wikimedia.org/wikipedia/commons/a/a3/Lcg_3d.gif){fig-align=\"center\"}\n\nThe important thing to note here is that if you specify the same generator values (a, c, m, and $X_0$), you will always get the same series of numbers. Since a, c, m are usually specified by the implementation, as a user, you should expect that if you specify the same seed, you will get the same results, every time.\n\n::: callout-warning\nIt is critically important to set your seed if you want the results to be reproducible and you are using an algorithm that depends on randomness.\n:::\n\nOnce you set your seed, the remaining results will only be reproducible if you generate the same set of random numbers every time.\n\n::: column-margin\nI once helped a friend fit a model for their masters thesis using Simulated Annealing (which relies on random seeds). We got brilliant results, but couldn't ever reproduce them, because I hadn't set the seed first and we never could figure out what the original seed was. Learn from my mistakes.\n:::\n\n::: callout-caution\n### Example: Setting Seeds for Reproducibility\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(342512)\n\n# Get 10 numbers after the seed is set\nsample(1:100, 10)\n##  [1] 65 51 64 21 45 53  3  6 43  8\n\n# Compute something else that depends on randomness\nmean(rnorm(50))\n## [1] -0.1095366\n\n# Get 10 more numbers\nsample(1:100, 10)\n##  [1]  4 57 69 10 76 15 67  1  3 91\n```\n:::\n\n\nCompare the results above to these results:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(342512)\n\n# Get 10 numbers after the seed is set\nsample(1:100, 10)\n##  [1] 65 51 64 21 45 53  3  6 43  8\n\n# Compute something else that depends on randomness\nmean(rnorm(30))\n## [1] -0.1936645\n\n# Get 10 more numbers\nsample(1:100, 10)\n##  [1]  49  37   6  34   9   3 100  43   7  29\n```\n:::\n\n\nNotice how the results have changed? To make my documents more reproducible, I will sometimes set a new seed at the start of an important chunk, even if I've already set the seed earlier. This introduces certain \"fixed points\" where results won't change immediately after I've re-set the seed. This is particularly important when I'm generating bootstrap estimates, fitting models, or simulating data for graphics experiments.\n:::\n\nPick your seed in any way you want. I tend to just randomly wiggle my fingers over the number keys, but I have also heard of people using the date in yyyymmdd format, favorite people's birthdays, the current time in hhmmss format... basically, you can use anything.\n\n## Built-in simulations from distributions\n\nOften, we can get away with just simulating data from a known distribution. As both R and python are meant for statistical computing, this is extremely easy by design.\n\n::: panel-tabset\n### R\n\nYou can see the various distribution options using `?Distributions`. In general, `dxxx` is the PDF/PMF, `pxxx` is the CDF, `qxxx` is the quantile function, and `rxxx` gives you random nubmers generated from the distribution. (`xxx`, obviously, is whatever distribution you're looking to use.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nset.seed(109025879)\n\ntibble(\n  norm = rnorm(500),\n  gamma = rgamma(500, shape = 3, scale = 1),\n  exp = rexp(500, rate = 1), # R uses a exp(-ax) \n  t = rt(500, df = 5),\n  chisq = rchisq(500, 5)\n) %>%\n  pivot_longer(1:5, names_to = \"dist\", values_to = \"value\") %>%\n  ggplot(aes(x = value)) + geom_density() + facet_wrap(~dist, scales = \"free\", nrow = 1)\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-3-1.png){width=3000}\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport random\nrandom.seed(109025879)\n\nimport pandas as pd\nimport numpy as np\n\nwide_df = pd.DataFrame({\n  \"norm\": np.random.normal(size=500),\n  \"gamma\": np.random.gamma(size=500, shape = 3, scale = 1),\n  \"exp\": np.random.exponential(size = 500, scale = 1),\n  \"t\": np.random.standard_t(df = 5, size = 500),\n  \"chisq\": np.random.chisquare(df = 5, size = 500)\n})\n\nlong_df = pd.melt(wide_df, id_vars = None, var_name = \"dist\", value_name = \"value\")\n\nfrom plotnine import *\n\n(ggplot(long_df, aes(x = \"value\")) + geom_density() + facet_wrap(\"dist\", scales=\"free\", nrow = 1))\n## <ggplot: (8761176073213)>\n## \n## /home/susan/Projects/Class/unl-stat850/stat850-textbook/renv/python/virtualenvs/renv-python-3.8/lib/python3.8/site-packages/plotnine/utils.py:371: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n## /home/susan/Projects/Class/unl-stat850/stat850-textbook/renv/python/virtualenvs/renv-python-3.8/lib/python3.8/site-packages/plotnine/facets/facet.py:390: PlotnineWarning: If you need more space for the x-axis tick text use ... + theme(subplots_adjust={'wspace': 0.25}). Choose an appropriate value for 'wspace'.\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-4-1.png){width=614}\n:::\n:::\n\n:::\n\n::: callout-tip\n### Try it out\n\n::: panel-tabset\n#### Problem\n\nGenerate variables x and y, where x is a sequence from -10 to 10 and y is equal to $x + \\epsilon$, $\\epsilon \\sim N(0, 1)$. Fit a linear regression to your simulated data (in R, `lm`, in Python, `sklearn.linear_model`'s `LinearRegression`).\n\nHint: Sample code for regression using sklearn [@menonLinearRegressionLines2018].\n\n##### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20572983)\ndata <- tibble(x = seq(-10, 10, .1), \n               y = x + rnorm(length(x)))\nregression <- lm(y ~ x, data = data)\nsummary(regression)\n## \n## Call:\n## lm(formula = y ~ x, data = data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -3.14575 -0.70986  0.03186  0.65429  2.40305 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -0.01876    0.06869  -0.273    0.785    \n## x            0.99230    0.01184  83.823   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.9738 on 199 degrees of freedom\n## Multiple R-squared:  0.9725,\tAdjusted R-squared:  0.9723 \n## F-statistic:  7026 on 1 and 199 DF,  p-value: < 2.2e-16\n```\n:::\n\n\n##### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport random\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nrandom.seed(20572983)\n\ndata = pd.DataFrame({'x': np.arange(-10, 10, .1)})\ndata['y'] = data.x + np.random.normal(size = data.x.size)\n\n# Fitting the regression and predictions\n# scikit-learn requires that we reshape everything into\n# nparrays before we pass them into the model.fit() function.\nmodel = LinearRegression().\\\n  fit(data.x.values.reshape(-1, 1),\\\n      data.y.values.reshape(-1, 1))\ndata['pred'] = model.predict(data.x.values.reshape(-1, 1))\n\n# Plotting the results\nimport matplotlib.pyplot as plt\nplt.clf()\n\nplt.scatter(data.x, data.y)\nplt.plot(data.x, data.pred, color='red')\nplt.show()\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-6-1.png){width=614}\n:::\n:::\n\n:::\n:::\n\n## Simulation to test model assumptions\n\nOne of the more powerful ways to use simulation in practice is to use it to test the assumptions of your model. Suppose, for instance, that your data are highly skewed, but you want to use a method that assumes normally distributed errors. How bad will your results be? Where can you trust the results, and where should you be cautious?\n\nExample from Telling Stories with Data: [Multilevel regression and post-stratification simulation with toddler bedtimes](https://www.tellingstorieswithdata.com/multilevel-regression-with-post-stratification.html#simulation---toddler-bedtimes). This example talks about how to take a biased sample and then recover the original unbiased estimates -- which is something you have to test using simulation to be sure it works, because you never actually know what the true population features are when you are working with real world data. When reading this example, you may not be all that interested with the specific model - but focus on the **process of simulating data for your analysis** so that you understand how and why you would want to simulate data in order to test a computational method.\n\n::: callout-caution\n\n### Example: Confidence Interval coverage rates\n\nSuppose, for instance, that we have a lognormal distribution (highly skewed) and we want to compute a 95% confidence interval for the mean of our data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(40295023)\n\nsim <- tibble(\n  id = rep(1:100, each = 25), # generate 100 samples of 25 points each\n  ln_x = rnorm(25*100), # generate the normal deviates\n  x = exp(ln_x), # transform into lognormal deviates\n) %>%\n  # this creates a 100-row data frame, with one row for each id. \n  # the columns x, ln_x are stored in the data list-column as a tibble.\n  nest(data = c(x, ln_x))\n  \nhead(sim)\n## # A tibble: 6 × 2\n##      id data             \n##   <int> <list>           \n## 1     1 <tibble [25 × 2]>\n## 2     2 <tibble [25 × 2]>\n## 3     3 <tibble [25 × 2]>\n## 4     4 <tibble [25 × 2]>\n## 5     5 <tibble [25 × 2]>\n## 6     6 <tibble [25 × 2]>\nsim$data[[1]]\n## # A tibble: 25 × 2\n##        x    ln_x\n##    <dbl>   <dbl>\n##  1 0.310 -1.17  \n##  2 0.622 -0.475 \n##  3 0.303 -1.19  \n##  4 1.05   0.0525\n##  5 0.529 -0.636 \n##  6 1.09   0.0891\n##  7 1.97   0.676 \n##  8 8.94   2.19  \n##  9 0.598 -0.514 \n## 10 0.183 -1.70  \n## # … with 15 more rows\n```\n:::\n\n\n\n\nYou want to assess the coverage probability of a confidence interval computed under two different modeling scenarios:\n\n1.  Working with the log-transformed values, ln(x), and then transform the computed interval back\n2.  Working with the raw values, x, compute an interval assuming the data are symmetric, essentially treating the lognormal distribution as if it were normal.\n\nUnder scenario 1, our theoretical interval should be exp((-1.96/5, 1.96/5)) (because $\\mu$ is 0, and $\\sigma$ is 1, so $SE(\\overline x) = 1/\\sqrt{25} = 1/5$). $(0.676,1.48)$\n\nUnder scenario 2, the expected value of the lognormal distribution is $\\exp(1/2) = 1.649$, the variance is $(\\exp(1) - 1)(\\exp(1)) = 4.671$ and our theoretical interval should be $(0.802, 2.496)$. This interval contains 0, which is implausible for lognormally distributed data.\n\nOur expected values are different under scenario 1 and scenario 2: in scenario 1 we are computing an interval for $\\mu$, in scenario 2, we are computing an interval for the population mean, which is $\\exp(\\mu + .5\\sigma^2)$. Both are valid quantities we might be interested in, but they do not mean the same thing.\n\n::: column-margin\nThe `purrr::map` notation specifies that we're using the `map` function from the `purrr` package. When functions are named generically, and there may be more than one package with a function name, it is often more readable to specify the package name along with the function.\n\n`purrr::map` takes an argument and for each \"group\" calls the compute_interval function, storing the results in `res`. So each row in `res` is a 1x2 tibble with columns lb and ub.\n\nThis pattern is very useful in all sorts of applications. I wish we had time to cover purrr explicitly, but I at least want to expose you to how clean it makes your code.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompute_interval <- function(x) {\n  s1 <- exp(mean(log(x)) + c(-1, 1) * qnorm(.975) * sd(log(x))/sqrt(length(x)))\n  s2 <- mean(x) + c(-1, 1) * qnorm(.975) * sd(x)/sqrt(length(x))\n  tibble(scenario = c(\"scenario_1\", \"scenario_2\"),\n         mean = c(1, exp(1/2)),\n         lb = c(s1[1], s2[1]), ub = c(s1[2], s2[2]),\n         in_interval = (lb < mean) & (ub > mean))\n}\n\n\nsim_long <- sim %>%\n  # This line takes each data entry and computes an interval for x.\n  # .$x is code for take the argument you passed in to map and get the x column\n  mutate(res = purrr::map(data, ~compute_interval(.$x))) %>%\n  # this \"frees\" res and we end up with two columns: lb and ub, for each scenario\n  unnest(res)\n  \n\nci_df <- tibble(scenario = c(\"scenario_1\", \"scenario_2\"),\n                mu = c(1, exp(1/2)),\n                lb = c(exp(-1.96/5), exp(.5) - 1.96*sqrt((exp(1) - 1)*exp(1))/5),\n                ub = c(exp(1.96/5), exp(.5) + 1.96*sqrt((exp(1) - 1)*exp(1))/5))\n\n\nggplot() + \n  geom_rect(aes(xmin = lb, xmax = ub, ymin = -Inf, ymax = Inf), \n            data = ci_df,\n            fill = \"grey\", alpha = .5, color = NA) + \n  geom_vline(aes(xintercept = mu), data = ci_df) + \n  geom_segment(aes(x = lb, xend = ub, y = id, yend = id, color = in_interval),\n               data = sim_long) + \n  scale_color_manual(values = c(\"red\", \"black\")) + \n  theme_bw() + \n  facet_wrap(~scenario)\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-9-1.png){width=2100}\n:::\n:::\n\n\nFrom this, we can see that working with the log-transformed, normally distributed results has better coverage probability than working with the raw data and computing the population mean: the estimates in the latter procedure have lower coverage probability, and many of the intervals are much wider than necessary; in some cases, the interval actually lies outside of the domain.\n\n:::\n\n::: column-margin\n[Here is a similar example worked through in SAS with IML](https://blogs.sas.com/content/iml/2016/09/08/coverage-probability-confidence-intervals.html). Note the use of BY-group processing to analyze each group at once - this is very similar to the use of `purrr::map()` in the R code.\n:::\n\n::: callout-caution\n\n### Example: Multilevel Regression and Post Stratification simulation\n\n[Multilevel regression and post-stratification simulation with toddler bedtimes](https://tellingstorieswithdata.com/16-mrp.html#simulation)\n\nThis example talks about how to take a biased sample and then recover the original unbiased estimates -- which is something you have to test using simulation to be sure it works, because you never actually know what the true population features are when you are working with real world data. When reading this example, you may not be all that interested with the specific model - but focus on the **process of simulating data for your analysis** so that you understand how and why you would want to simulate data in order to test a computational method.\n\n:::\n\n::: callout-caution\n\n### Example: Regression and high-leverage points\n\nWhat happens if we have one high-leverage point (e.g. a point which is an outlier in both x and y)? How pathological do our regression coefficient estimates get?\n\nThe challenging part here is to design a data generating mechanism.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngen_data <- function(n = 30, o = 1, error_sd = 2) {\n  # generate the main part of the regression data\n  data <- tibble(x = rnorm(n = n - o, mean = seq(-10, 10, length.out = n - o), sd = .1),\n                 y = x + rnorm(length(x), mean = 0, sd = error_sd))\n  # generate the outlier - make it at ~(-10, 5)\n  outdata <- tibble(x = rnorm(o, -10), y = rnorm(o, 5, error_sd))\n  bind_rows(data, outdata)\n}\n\nsim_data <- tibble(\n  id = 1:300,\n  o = rep(0:2, each = 100),\n  # call gen_data for each row in sim_data, but don't really use id as a parameter.\n  data = purrr::map(o, ~gen_data(o = .)) \n)\n\nhead(sim_data)\n## # A tibble: 6 × 3\n##      id     o data             \n##   <int> <int> <list>           \n## 1     1     0 <tibble [30 × 2]>\n## 2     2     0 <tibble [30 × 2]>\n## 3     3     0 <tibble [30 × 2]>\n## 4     4     0 <tibble [30 × 2]>\n## 5     5     0 <tibble [30 × 2]>\n## 6     6     0 <tibble [30 × 2]>\n\n# plot a few datasets just to check they look like we expect:\nsim_data %>%\n  filter(id %% 100 < 3) %>%\n  unnest(data) %>%\n  ggplot(aes(x = x, y = y)) + \n  geom_point() + \n  facet_grid(id %% 100 ~ o )\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-10-1.png){width=2100}\n:::\n\n```{.r .cell-code}\n\n\nlibrary(broom) # the broom package cleans up model objects to tidy form\n\nsim_data <- sim_data %>%\n  # fit linear regression\n  mutate(model = purrr::map(data, ~lm(y ~ x, data = .)))  %>%\n  mutate(tidy_model = purrr::map(model, tidy))\n\n# Get the coefficients out\ntidy_coefs <- select(sim_data, id, o, tidy_model) %>%\n  unnest(tidy_model) %>%\n  mutate(group = case_when(o == 0 ~ \"No HLPs\",\n                           o == 1 ~ \"1 HLP\",\n                           o == 2 ~ \"2 HLPs\") %>%\n           factor(levels = c(\"No HLPs\", \"1 HLP\", \"2 HLPs\")))\n\nggplot(tidy_coefs, aes(x = estimate, color = group)) + \n  facet_grid(term ~ .) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-10-2.png){width=2100}\n:::\n:::\n\n\nObviously, you should experiment with different methods of generating a high-leverage point (maybe use a different distribution?) but this generating mechanism is simple enough for our purposes and shows that the addition of high leverage points biases the true values (slope = 1, intercept = 0).\n\n:::\n\n::: callout-tip\n### Try it out \n\n::: panel-tabset\n\n#### Problem\n\nLet's explore what happens to estimates when certain observations are censored. Suppose we have a poorly-designed digital thermometer which cannot detect temperatures above 102$^\\circ F$; for these temperatures, the thermometer will record a value of 102.0.\n\nIt is estimated that normal body temperature for dogs and cats is 101 to 102.5 degrees Fahrenheit, and values above 104 degrees F are indicative of illness. Given that you have this poorly calibrated thermometer, design a simulation which estimates the average temperature your thermometer would record for a sample of 100 dogs or cats, and determine the magnitude of the effect of the thermometer's censoring.\n\n#### Hint\n\nIf most pets have a normal body temperature between 101 and 102.5 degrees, can you use these bounds to determine appropriate parameters for a normal distribution? What if you assume that 101 and 102.5 are the 2SD bounds?\n\n#### General Solution\n\nIf 101 and 102.5 are the anchor points we have, let's assume that 95% of normal pet temperatures fall in that range. So our average temperature would be 101.75, and our standard deviation would be .75/2 = 0.375.\n\nWe can simulate 1000 observations from $N(101.75, 0.375)$, create a new variable which truncates them at 102, and compute the mean of both variables to determine just how biased our results are.\n\n#### R Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(204209527)\ndogtemp <- tibble(\n  actual = rnorm(1000, 101.75, 0.375),\n  read = pmin(actual, 102)\n) \ndogtemp %>%\n  summarize_all(mean)\n## # A tibble: 1 × 2\n##   actual  read\n##    <dbl> <dbl>\n## 1   102.  102.\n```\n:::\n\n\nThe effect of the thermometer's censoring is around 0.06 degrees F.\n\n#### Python Code\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport random\n\nrandom.seed(204209527)\ndogtemp = pd.DataFrame({\n  \"actual\": np.random.normal(size = 1000, loc = 101.75, scale = 0.375)\n})\ndogtemp['read'] = np.minimum(dogtemp.actual, 102)\n\nnp.diff(dogtemp.mean())\n## array([-0.0584365])\n```\n:::\n\n\nThe effect of the thermometer's censoring is around 0.06 degrees F.\n:::\n\n:::\n\n## Monte Carlo methods\n\n[Monte carlo methods](https://en.wikipedia.org/wiki/Monte_Carlo_method) [@MonteCarloMethod2022] are methods which rely on repeated random sampling in order to solve numerical problems. Often, the types of problems approached with MC methods are extremely difficult or impossible to solve analytically.\n\nIn general, a MC problem involves these steps:\n\n1.  Define the input domain\n2.  Generate inputs randomly from an appropriate probability distribution\n3.  Perform a computation using those inputs\n4.  Aggregate the results.\n\n\n::: {.callout-caution collapse=true}\n\n### Example: Sum of Uniform Random Variables\n\n::: panel-tabset\n\n#### Problem\nLet's try it out by using MC simulation to estimate the number of uniform (0,1) random variables needed for the sum to exceed 1.\n\nMore precisely, if $u_i \\sim U(0,1)$, where \\sum\\_{i=1}\\^k u_i \\> 1, what is the expected value of $k$?\n\n#### Defining Steps\n\n1.  In this simulation, our input domain is \\[0,1\\].\n2.  Our input is $u_i \\sim U(0,1)$\n3.  We generate new $u_i$ until $\\sum_{i=1}^k > 1$ and save the value of $k$\n4.  We average the result of $N$ such simulations.\n\n#### R Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# It's easier to think through the code if we write it inefficiently first\nsim_fcn <- function() {\n  usum <- 0\n  k <- 0\n  # prevent infinite loops by monitoring the value of k as well\n  while (usum < 1 & k < 15) {\n    usum <- runif(1) + usum\n    k <- k + 1\n  }\n  return(k)\n}\n\nset.seed(302497852)\nres <- tibble(k = replicate(1000, sim_fcn(), simplify = T))\n\nmean(res$k)\n## [1] 2.717\n```\n:::\n\n\nIf we want to see whether the result converges to something, we can increase the number of trials we run:\n\n\n::: {.cell hash='simulation_cache/html/unnamed-chunk-15_3fff0bbba104effbecc2dc58c12263ff'}\n\n```{.r .cell-code}\nset.seed(20417023)\n\nsim_res <- tibble(samp = replicate(250000, sim_fcn(), simplify = T)) \n\nsim_res <- sim_res %>%\n  mutate(running_avg_est = cummean(samp),\n         N = row_number())\n\nggplot(aes(x = N, y = running_avg_est), data = sim_res) + \n  geom_hline(yintercept = exp(1), color = \"red\") + \n  geom_line()\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-15-1.png){width=2100}\n:::\n:::\n\n\n#### Python Code\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport random\nimport pandas as pd\n\n\ndef sim_fcn():\n  usum = 0\n  k = 0\n  # prevent infinite loops by monitoring the value of k as well\n  while usum < 1 and k < 15:\n    # print(\"k = \", k)\n    usum = np.random.uniform(size=1) + usum\n    k += 1\n  return k\n\nrandom.seed(302497852)\nres = pd.DataFrame({\"k\": [sim_fcn() for _ in range(1000)]})\n```\n:::\n\n\nIf we want to see whether the result converges to something, we can increase the number of trials we run:\n\n\n::: {.cell hash='simulation_cache/html/unnamed-chunk-17_cd4b66e578ec640a81c4402da1600a34'}\n\n```{.python .cell-code}\nrandom.seed(20417023)\n\nsim_res = pd.DataFrame({\"k\": [sim_fcn() for _ in range(250000)]})\nsim_res['running_avg_est'] = sim_res.k.expanding().mean()\nsim_res['N'] = np.arange(len(sim_res))\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.clf()\n\ngraph = sns.lineplot(data = sim_res, x = 'N', y = 'running_avg_est', color = \"black\")\ngraph.axhline(y = np.exp(1), xmin = 0, xmax = 1, color = \"red\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-17-1.png){width=614}\n:::\n:::\n\n\n#### Learn More\n\nThe expected number of uniform RV draws required to sum to 1 is $e$!\n\n[Explanation of why this works](https://www.jstor.org/stable/2685243)\n\n:::\n\n:::\n\nMonte Carlo methods are often used to approximate the value of integrals which do not have a closed-form (in particular, these integrals tend to pop up frequently in Bayesian methods). \n\n::: callout-caution\n### Example: Integration\n\n::: panel-tabset\n\n#### Problem\nSuppose you want to integrate $$\\int_0^1 x^2 \\sin \\left(\\frac{1}{x}\\right) dx$$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-18-1.png){width=50%}\n:::\n:::\n\n\nYou could set up Riemann integration and evaluate the integral using a sum over $K$ points, but that approach only converges for smooth functions (and besides, that's boring Calc 2 stuff, right?).\n\nInstead, let's observe that this is equivalent to $\\int_0^1 x^2 \\sin \\left(\\frac{1}{x}\\right) \\cdot 1 dx$, where $p(x) = 1$ for a uniform random variable. That is, this integral can be written as the expected value of the function over the interval $[0,1]$. What if we just generate a bunch of uniform(0,1) variables, evaluate the value of the function at that point, and average the result?\n\n#### R Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20491720)\nfn <- function(x)  x^2 * sin(1/x)\n\nsim_data <- tibble(x = runif(100000),\n                   y = fn(x))\nmean(sim_data$y)\n## [1] 0.28607461\n```\n:::\n\n\n#### Python Code\n\n\n::: {.cell}\n\n```{.python .cell-code}\nrandom.seed(20491720)\n\ndef fn(x):\n  return x**2 * np.sin(1/x)\n\nsim_data = pd.DataFrame({\"x\": np.random.uniform(size = 100000)})\nsim_data['y'] = fn(sim_data.x)\n\nsim_data.y.mean()\n## 0.2853579113268654\n```\n:::\n\n\n#### Proof of Convergence\n\nYou can use the law of large numbers to prove that this approach will converge. [Example modified from this set of lecture notes](http://faculty.washington.edu/yenchic/17Sp_403/Lec2_MonteCarlo.pdf) [@chenLectureMonteCarlo2017]\n\n:::\n\n:::\n\n::: callout-tip\n### Try it out \n\n::: panel-tabset\n\n#### Problem\nBuffon's needle is a mathematical problem which can be boiled down to a simple physical simulation. Read [this science friday description of the problem](https://www.sciencefriday.com/articles/estimate-pi-by-dropping-sticks/) and develop a monte carlo simulation method which estimates $\\pi$ using the Buffon's needle method. Your method should be a function which\n\n-   allows the user to specify how many sticks are dropped\n-   plots the result of the physical simulation\n-   prints out a numerical estimate of pi.\n\n#### R code\n\nLet's start out with horizontal lines at 0 and 1, and set our stick length to 1. We need to randomly generate a position (of one end of the stick) and an angle. The position in $x$ doesn't actually make much of a difference (since what we care about is the $y$ coordinates), but we can draw a picture if we generate $x$ as well.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nneedle_sim <- function(sticks = 100) {\n  df <- tibble(xstart = runif(sticks, 0, 10), \n         ystart = runif(sticks, 0, 1), \n         angle = runif(sticks, 0, 360),\n         xend = xstart + cos(angle/180*pi), \n         yend = ystart + sin(angle/180*pi)\n  ) %>%\n    # We can see if a stick crosses a line if the floor() function of ystart is \n    # different than floor(yend). \n    # Note this only works for integer line values.\n  mutate(crosses_line = floor(ystart) != floor(yend)) \n  \n  \n  gg <- ggplot() + \n  geom_hline(yintercept = c(0, 1)) + \n  geom_segment(aes(x = xstart, y = ystart, xend = xend, yend = yend,\n                   color = crosses_line), data = df) + \n  coord_fixed()\n  \n  return(list(est = 2 * sticks / sum(df$crosses_line), plot = gg))\n}\n\nneedle_sim(10)\n## $est\n## [1] 2.8571429\n## \n## $plot\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-21-1.png){width=2100}\n:::\n\n```{.r .cell-code}\n\nneedle_sim(100)\n## $est\n## [1] 2.8985507\n## \n## $plot\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-21-2.png){width=2100}\n:::\n\n```{.r .cell-code}\n\nneedle_sim(1000)\n## $est\n## [1] 3.1298905\n## \n## $plot\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-21-3.png){width=2100}\n:::\n\n```{.r .cell-code}\n\nneedle_sim(10000)\n## $est\n## [1] 3.1235358\n## \n## $plot\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-21-4.png){width=2100}\n:::\n:::\n\n\n#### Python Code\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef needle_sim(sticks = 100):\n  df = pd.DataFrame({\n    \"xstart\": np.random.uniform(0, 10, size = sticks),\n    \"ystart\": np.random.uniform(0, 1, size = sticks),\n    \"angle\": np.random.uniform(0, 360, size = sticks)\n  })\n  \n  df['xend'] = df.xstart + np.cos(df.angle/180*np.pi)\n  df['yend'] = df.ystart + np.sin(df.angle/180*np.pi)\n  df['crosses_line'] = np.floor(df.ystart) != np.floor(df.yend)\n  \n  return df\n\ndata = needle_sim(100000)\ndata['N'] = np.arange(len(data)) + 1\ndata['cum_est'] = 2*data.N / data.crosses_line.expanding().sum()\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.clf()\n\ngraph = sns.lineplot(data = data, x = \"N\", y = \"cum_est\", color = \"black\")\ngraph.axhline(y = np.pi, xmin = 0, xmax = 1, color = \"red\")\nplt.show()\n```\n\n::: {.cell-output-display}\n![](simulation_files/figure-html/unnamed-chunk-22-1.png){width=614}\n:::\n:::\n\n:::\n:::\n\n\n## Other Resources\n\n-   [Simulation](https://bookdown.org/rdpeng/rprogdatascience/simulation.html) (R programming for Data Science chapter)\n\n-   [Simulation](http://rstudio-pubs-static.s3.amazonaws.com/302783_75485bd9eb4646698f534a4833a026e5.html#_simulation_) - R Studio lesson\n\n-   [Simulation, focusing on statistical modeling](http://www.columbia.edu/~cjd11/charles_dimaggio/DIRE/resources/R/simRreg.pdf) (R)\n\n-   [Simulating Data with SAS](https://support.sas.com/content/dam/SAS/support/en/books/simulating-data-with-sas/65378_excerpt.pdf) (Excerpt)\n\n-   [Simulating a Drunkard's Walk in 2D in SAS](https://blogs.sas.com/content/iml/2015/08/12/2d-drunkards-walk.html)\n\n-   [Simulation from a triangle distribution (SAS)](https://blogs.sas.com/content/iml/2015/07/22/sim-triangular-distrib.html)\n\n-   [Simulating the Monty Hall problem (SAS)](https://blogs.sas.com/content/iml/2015/04/01/monty-hall.html)\n\n-   [When to use `purrr`](https://education.rstudio.com/blog/2020/07/teaching-the-tidyverse-in-2020-part-4-when-to-purrr/) (part of the 'teaching the tidyverse' series) - essentially, purrr is a great intro to functional programming, but there are other ways to solve iterative problems in R as well, and some of them are easier than purrr (but purrr is a general approach that is very powerful).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}