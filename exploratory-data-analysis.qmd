---
editor_options: 
  markdown: 
    wrap: 72
---

# Exploratory Data Analysis

::: callout-note
## Extra Reading {.unnumbered}

[The EDA chapter in R for Data Science](https://r4ds.had.co.nz/exploratory-data-analysis.html) [\@r4ds] is very good at
explaining what the goals of EDA are, and what types of questions you
will typically need to answer in
EDA. Much of the
material in this chapter is based at least in part on the R4DS chapter.
:::

![(Image from ) The EDA lifecycle starts with data collection and is
primarily a cycle between checking data types, assessing distributions,
feature engineering, and model iteration. These tasks are supported by
summary statistics, visualization, and
modeling.](images/eda/an-EDA-lifecycle.png){fig-align="center"
width="75%"}
<!-- https://www.mrdbourke.com/content/images/size/w1000/2019/09/an-EDA-lifecycle.png -->

Major components of Exploratory Data Analysis (EDA):

-   generating questions about your data
-   look for answers to the questions (visualization, transformation,
    modeling)
-   use answers to refine the questions and generate new questions

EDA is an iterative process. It is like brainstorming - you start with
an idea or question you might have about the data, investigate, and then
generate new ideas. EDA is useful even when you are relatively familiar
with the type of data you're working with: in any dataset, it is good to
make sure that you know the quality of the data as well as the
relationships between the variables in the dataset.

EDA is important because it helps us to know what challenges a
particular data set might bring, what we might do with it. Real data is
often messy, with large amounts of cleaning that must be done before
statistical analysis can commence.

While in many classes you'll be given mostly clean data, you do need to
know how to clean your own data up so that you can use more interesting
data sets for projects (and for fun!). EDA is an important component to
learning how to work with messy data.

::: .callout-note
In this section, I will mostly be using the plot commands that come with
base R/python and require no extra packages. The R for Data Science book
[@r4ds] shows plot commands which use the `ggplot2` library. I'll show
you some plots from ggplot here as well, but you don't have to
understand how to generate them yet. We will learn more about ggplot2
later, though if you want to start using it now, you may.
:::

## A Note on Language Philosophies {.unnumbered}

It is usually relatively easy to get summary statistics from a dataset,
but the "flow" of EDA is somewhat different depending on the language
patterns.

> You must realize that R is written by experts in statistics and
> statistical computing who, despite popular opinion, do not believe
> that everything in SAS and SPSS is worth copying. Some things done in
> such packages, which trace their roots back to the days of punched
> cards and magnetic tape when fitting a single linear model may take
> several days because your first 5 attempts failed due to syntax errors
> in the JCL or the SAS code, still reflect the approach of "give me
> every possible statistic that could be calculated from this model,
> whether or not it makes sense". The approach taken in R is different.
> The underlying assumption is that the useR is thinking about the
> analysis while doing it. -- Douglas Bates

I provide this as a historical artifact, but it does explain the
difference between the approach to EDA and model output in R and Python,
and the approach in SAS, which you may see in your other statistics
classes. This is not (at least, in my opinion) a criticism -- the SAS
philosophy dates back to the mainframe and punch card days, and the
syntax and output still bear evidence of that -- but it is worth noting.

In R and in Python, you will have to specify each piece of output you
want, but in SAS you will get more than you ever wanted with a single
command. Neither approach is wrong, but sometimes one is preferable over
the other for a given problem.

## Generating EDA Questions

I very much like the two quotes in the @r4ds section on EDA Questions:

> There are no routine statistical questions, only questionable
> statistical routines. --- Sir David Cox

> Far better an approximate answer to the right question, which is often
> vague, than an exact answer to the wrong question, which can always be
> made precise. --- John Tukey

As statisticians, we are concerned with variability by default. This is
also true during EDA: we are interested in variability (or sometimes,
lack thereof) in the variables in our dataset, including the
co-variability between multiple variables.

We may assess variability using pictures or numerical summaries:

-   histograms or density plots (continuous variables)
-   column plots (categorical variables)
-   boxplots
-   5 number summaries (min, 25%, mean, 75%, max)
-   tabular data summaries (for categorical variables)

In many cases, this gives us a picture of both variability and the
"typical" value of our variable.

Sometimes we may also be interested in identifying unusual values:
outliers, data entry errors, and other points which don't conform to our
expectations. These unusual values may show up when we generate pictures
and the axis limits are much larger than expected.

We also are usually concerned with missing values - in many cases, not
all observations are complete, and this missingness can interfere with
statistical analyses. It can be helpful to keep track of how much
missingness there is in any particular variable and any patterns of
missingness that would impact the eventual data
analysis[^exploratory-data-analysis-1].

[^exploratory-data-analysis-1]: One package for this process in R is
    `naniar` [@tierneyNaniarDataStructures2021].

If you are having trouble getting started on EDA,
@danielbourkeGentleIntroductionExploratory2019 provides a nice checklist
to get you thinking:

> 1.  What question(s) are you trying to solve (or prove wrong)?
> 2.  What kind of data do you have and how do you treat different
>     types?
> 3.  What's missing from the data and how do you deal with it?
> 4.  Where are the outliers and why should you care about them?
> 5.  How can you add, change or remove features to get more out of your
>     data?

## Useful EDA Techniques

In this chapter, we'll explore the [pokemon
data](https://github.com/shahinrostami/pokemon_dataset/blob/master/pokemon_gen_1_to_8.csv)
in [shahinrostami](https://github.com/shahinrostami/pokemon_dataset)'s
github repository. This data has a number of categorical and continuous
variables that should allow for a reasonable demonstration of a number
of techniques for exploring data.

::: panel-tabset
### R {.unnumbered}

```{r read-poke-data}
library(readr)
url <- "https://raw.githubusercontent.com/shahinrostami/pokemon_dataset/master/pokemon_gen_1_to_8.csv"
poke <- read_csv(url)[,-c(1, 4, 5)] # skip extra columns
```

### Python {.unnumbered}

```{python read-poke-data-py}
import pandas as pd
poke = pd.read_csv("https://raw.githubusercontent.com/shahinrostami/pokemon_dataset/master/pokemon_gen_1_to_8.csv")
poke = poke.drop(["Unnamed: 0", "german_name", "japanese_name"], axis = 1) # Drop some extra cols
```
:::

### Numerical Summary Statistics

::: panel-tabset
#### R: summary {.unnumbered}

The first, and most basic EDA command in R is `summary()`.

For numeric variables, `summary` provides 5-number summaries plus the
mean. For categorical variables, `summary` provides the length of the
variable and the Class and Mode. For factors, `summary` provides a table
of the most common values, as well as a catch-all "other" category.

```{r readr-eda}
# Make types into factors to demonstrate the difference
poke$type_1 <- factor(poke$type_1)
poke$type_2 <- factor(poke$type_2)

summary(poke[,3:12])
```

One common question in EDA is whether there are missing values or other
inconsistencies that need to be handled. `summary()` provides you with
the NA count for each variable, making it easy to identify what
variables are likely to cause problems in an analysis.

There is one pokemon who appears to not have a weight specified. Let's
investigate further:

```{r poke-weight}
poke[is.na(poke$weight_kg),] # Show any rows where weight.kg is NA
```

This is the last row of our data frame, and this pokemon appears to have
many missing values.

#### Python: describe {.unnumbered}

The most basic EDA command in pandas is `df.describe()` (which operates
on a DataFrame named `df`). Like `summary()` in R, `describe()` provides
a 5-number summary for numeric variables. For categorical variables,
`describe()` provides the number of unique values, the most common
value, and the frequency of that common value.

```{python poke}
poke.iloc[:,2:11].describe() # describe only shows numeric variables by default

# You can get categorical variables too if that's all you give it to show
poke['status'].describe()
```

#### R: skimr {.unnumbered}

An R package that is incredibly useful for this type of dataset
exploration is `skimr`.

```{r skimr-poke-demo}
library(skimr)
skim(poke)
```

`skim` provides a beautiful table of summary statistics along with a
sparklines-style histogram of values, giving you a sneak peek at the
distribution.

#### python: skimpy {.unnumbered}

There is a similar package to `skimr` in R called `skimpy` in Python.

```{python skimpy-poke-demo}
from skimpy import skim
skim(poke)
```
:::

## References
