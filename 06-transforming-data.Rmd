# Transforming Data {#transforming-data}

> “Happy families are all alike; every unhappy family is unhappy in its own way.” –– Leo Tolstoy

> “Tidy datasets are all alike, but every messy dataset is messy in its own way.” –– Hadley Wickham

## Module Objectives {-}

- Reshape data
- Transform variables to support analysis and visualization of data
- Join tables together in order to create a single coherent dataset

Most of the time, data does not come in a format suitable for analysis. Spreadsheets are generally optimized for data *viewing*, rather than for statistical analysis - they may be laid out so that there are multiple observations in a single row (e.g., commonly a year's worth of data, with monthly observations in each column). 

Unfortunately, this type of data structure is not usually useful to us when we analyze or visualize the data. 

## Identifying the problem: Messy data

These datasets all display the same data: TB cases documented by the WHO in Afghanistan, Brazil, and China, between 1999 and 2000. There are 4 variables: country, year, cases, and population, but each table has a different layout.
```{r, message = F}
library(tidyverse)
```

```{r, echo = F}
knitr::kable(table1, caption = "Table 1")
```

Here, each observation is a single row, each variable is a column, and everything is nicely arranged for e.g. regression or statistical analysis. We can easily compute another measure, such as cases per 100,000 population, by taking cases/population * 100000 (this would define a new column). 


```{r, echo = F}
knitr::kable(table2, caption = "Table 2")
```

Here, we have 4 columns again, but we now have 12 rows: one of the columns is an indicator of which of two numerical observations is recorded in that row; a second column stores the value. This form of the data is more easily plotted in e.g. ggplot2, if we want to show lines for both cases and population, but computing per capita cases would be much more difficult in this form than in the arrangement in table 1. 


```{r, echo = F}
knitr::kable(table3, caption = "Table 3")
```

This form has only 3 columns, because the rate variable (which is a character) stores both the case count and the population. We can't do *anything* with this format as it stands, because we can't do math on data stored as characters. However, this form might be easier to read and record for a human being. 


```{r, echo = F}
knitr::kable(table4a, caption = "Table 4a")
knitr::kable(table4b, caption = "Table 4b")
```

In this form, we have two tables - one for population, and one for cases. Each year's observations are in a separate column. This format is often found in separate sheets of an excel workbook. To work with this data, we'll need to transform each table so that there is a column indicating which year an observation is from, and then merge the two tables together by country and year. 


```{r, echo = F}
knitr::kable(table5, caption = "Table 5")
```

Table 5 is very similar to table 3, but the year has been separated into two columns - century, and year. This is more common with year, month, and day in separate columns  (or date and time in separate columns), often to deal with the fact that spreadsheets don't always handle dates the way you'd hope they would. 


These variations highlight the principles which can be said to define a tidy dataset:
1. Each variable must have its own column
2. Each observation must have its own row
3. Each value must have its own cell

<div class="tryitout">
### Try it out {-}
Go back through the 5 tables and determine whether each table is tidy, and if it is not, which rule or rules it violates. Figure out what you would have to do in order to compute a standardized TB infection rate per 100,000 people. 
<details><summary>Solution</summary>
1. table1 - this is tidy data. Computing a standardized infection rate is as simple as creating the variable rate = cases/population*100,000.
2. table2 - each variable does not have its own column (so a single year's observation of one country actually has 2 rows). Computing a standardized infection rate requires moving cases and population so that each variable has its own column, and then you can proceed using the process in 1.
3. table3 - each value does not have its own cell (and each variable does not have its own column). In Table 3, you'd have to separate the numerator and denominator of each cell, convert each to a numeric variable, and then you could proceed as in 1. 
4. table4a and table 4b - there are multiple observations in each row because there is not a column for year. To compute the rate, you'd need to "stack" the two columns in each table into a single column, add a year column that is 1999, 1999, 1999, 2000, 2000, 2000, and then merge the two tables. Then you could proceed as in 1. 
5. table 5 - each variable does not have its own column (there are two columns for year, in addition to the issues noted in table3). Computing the rate would be similar to table 3; the year issues aren't actually a huge deal unless you plot them, at which point 99 will seem to be bigger than 00 (so you'd need to combine the two year columns together first). 
</details>
</div>

It is actually impossible to have a table that violates only one of the rules of tidy data - you have to violate at least two. So a simpler way to state the rules might be: 

1. Each dataset goes into its own table (or tibble, if you are using R)
2. Each variable gets its own column

By the end of this module, you should have the skills to "tidy" each of these tables. 

## String operations: Creating new variables and separating multi-variable columns

Nearly always, when multiple variables are stored in a single column, they are stored as character variables. There are many different "levels" of working with strings in programming, from simple find-and-replaced of fixed (constant) strings to regular expressions, which are extremely powerful (and extremely complicated). 

> Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems. - Jamie Zawinski

![Alternately, the xkcd version of the above quote](https://imgs.xkcd.com/comics/perl_problems.png)

The tidyverse package to deal with strings is [`stringr`](https://stringr.tidyverse.org/). The functions in stringr take the form of `str_XXX` where XXX is a verb. So `str_split()`, `str_replace()`, `str_remove()`, `str_to_lower()` all should make some sense.

```{r, eval = F}
college_data <- read_csv("https://ed-public-download.app.cloud.gov/downloads/Most-Recent-Cohorts-All-Data-Elements.csv") 
college_data2 <- college_data %>%
  select(UNITID, INSTNM, CITY, STABBR, ZIP, ACCREDAGENCY, INSTURL, PREDDEG, MAIN, NUMBRANCH, HIGHDEG, CONTROL, ST_FIPS, LOCALE, LATITUDE, LONGITUDE) %>%
  mutate(PREDDEG = factor(PREDDEG, levels = 0:4, labels = c("Not classified", "Predominantely certificate-degree granting", "Predominantely associate's-degree granting", "Predominantly bachelor's-degree granting", "Entirely graduate-degree granting")),
         MAIN = factor(MAIN, levels = 0:1, labels = c("Not main campus", "main campus")),
         HIGHDEG = factor(HIGHDEG, levels = 0:4, labels = c("Non-degree granting", "Certificate", "Associate", "Bachelors", "Graduate")),
         CONTROL = factor(CONTROL, levels = 1:3, labels = c("Public", "Private Non Profit", "Private For Profit")))
readr::write_csv(college_data2, "data/College_Data_Abbrev.csv")


college_fips <- read_csv("data/CollegeFips.csv", col_names = F) %>%
  set_names(c("ST_FIPS", "State")) %>%
  mutate_all(as.character)

college_data2 %>% select(STABBR, ST_FIPS) %>%
  mutate(ST_FIPS = as.character(ST_FIPS)) %>%
  unique() %>%
  left_join(college_fips) %>%
  write_csv("data/College_FIPS_Abbr.csv")

college_data2 <- left_join(college_data2, college_fips)
readr::write_csv(college_data2, "data/College_Data_Abbrev.csv", na = '.')
```

For this example, we'll use a subset of the US Department of Education College Scorecard data. [Documentation](https://collegescorecard.ed.gov/data/documentation/), [Data](https://collegescorecard.ed.gov/data/). I've selected a few columns from the institution-level data available on the College Scorecard site. 

<details><summary>Let's take a look</summary>
```{r}
college <- read_csv("data/College_Data_Abbrev.csv", guess_max = 5000, na = '.')
str(college)
```

```{sashtml sas-college-read-data}
libname classdat "/home/susan/Projects/Class/unl-stat850/2020-stat850/sas/";

filename fileloc '~/Projects/Class/unl-stat850/2020-stat850/data/College_Data_Abbrev.csv';
PROC IMPORT  datafile = fileloc out=classdat.college REPLACE
DBMS = csv; /* comma delimited file */
GUESSINGROWS=500;
GETNAMES = YES;
RUN;

PROC PRINT DATA = classdat.college (obs = 5);
RUN;
```
</details>


<details><summary>What proportion of the schools operating in each state have the state's name in the school name?</summary>

We'll use `str_detect()` to look for the state name in the college name. 
```{r, fig.width = 4, fig.height = 8, out.width = 4}
# Outside the pipe
str_detect(college$INSTNM, pattern = college$State)

# Using the pipe and mutate:
college <- college %>%
  mutate(uses_st_name = str_detect(INSTNM, State))

# By state - percentage of institution names
college %>%
  group_by(State) %>%
  summarize(pct_uses_st_name = mean(uses_st_name), n = n()) %>%
  filter(n > 5) %>% # only states/territories with at least 5 schools
  # Reorder state factor level by percentage that uses state name
  mutate(State = reorder(State, -pct_uses_st_name)) %>%
  ggplot(data = ., aes(x = State, y = pct_uses_st_name)) + 
  geom_col() + coord_flip() + 
  geom_text(aes(y = 1, label = paste("Total Schools:", n)), hjust = 1)
```

In SAS, we use `find(x, pattern, 't')` to find the location of the pattern, which is 0 if the pattern is not found. To get something equivalent to `str_detect`, we just test whether this quantity is greater than 0. (The R equivalent of `find` is `str_locate()`). 

Note that SAS pads character fields with spaces so that they are all the same length. So if we want to test for "Alabama    " we could omit the 't' option in the command, but since we usually don't want that, we need to tell SAS to trim the fields before searching for the pattern. 

```{sashtml sas-college-find}
libname classdat "/home/susan/Projects/Class/unl-stat850/2020-stat850/sas/";

DATA collegetmp;
set classdat.college;
uses_st_name = find(INSTNM, State, 't') GT 0;
RUN;


PROC PRINT DATA = collegetmp (obs = 5);
RUN;
```
</details>

<details><summary>What are some common substrings in a set of text?</summary>
For this, we'll start with working with the single column `INSTNM`. 

```{r}
head(college$INSTNM) %>% str_split(., " ") # Split on every space

# We may need to fix certain things that should stay together
# But doing too much of that gets tedious...
str_replace(college$INSTNM, "A & M", "A&M") %>%
  head() %>% 
  str_split(., "[ -]") # This pattern says "either ' ' or '-'" 
                       # (but the - has to be at the start or the end)
```
So we could take the time to clean up everything, making sure that e.g. San Diego is treated as a single word, but that's a pain in the rear. Instead, let's just see what happens if we brute-force it. 
```{r}
tmp <- college %>%
  select(INSTNM, State) %>% 
  mutate(name_words = str_split(INSTNM, '[ -]')) # This is a list-column
tmp
unnest(tmp) # Unnest duplicates rows so that the expanded data frame has the 
            # same structure as the original data
```
List columns are one way to maintain tidy data. They allow you to have several "sub-observations" for each observation and are useful for precisely cases like this, where there are uneven numbers of words in each university's name. We're not going to focus on list columns, but if you're interested, check out `purrr` and this [excellent tutorial](https://jennybc.github.io/purrr-tutorial/). 
```{r}
unnest(tmp) %>% 
  pull(name_words) %>% # this pulls out a single column
  table() %>% 
  sort(decreasing = T) %>% 
  head(50)
```

In SAS, this is a bit more tricky. Most people I know that use both SAS and R will do the data cleaning in R once things get complicated, and then read the clean data in to SAS. That's a valid approach, but it's worth seeing what has to be done in SAS this once. As we get further into this class, I'll probably be more willing to say "we're just going to use R for this" for two reasons - 1. I know R better, and 2. R is generally better at handling the weird stuff; SAS is built to quickly handle things that are already formatted in a reasonable way. SAS seems to be highly preferred for e.g. fitting mixed/linear models, but it isn't the easiest tool to use for data cleaning. 

But, in this particular case, there is [documentation about how to break a sentence into words](https://blogs.sas.com/content/iml/2016/07/11/break-sentence-into-words-sas.html) in SAS. 
```{sashtml sas-college-split-string-words}
libname classdat "/home/susan/Projects/Class/unl-stat850/2020-stat850/sas/";
DATA collegename;
SET classdat.college;
numWords = countw(INSTNM, " ");
DO i = 1 TO numWords;
  word = scan(INSTNM, i, " ");
  OUTPUT;
END;
KEEP word numWords;
;

PROC PRINT DATA=collegename (obs = 30);
run;

PROC FREQ DATA=collegename ORDER=FREQ;
TABLES word / MAXLEVELS=30;
RUN;
```
</details>

There's one final string-related task that is fairly commonly encountered, and that is in e.g. the case of Table 3 above, where one column has two (or more) variables worth of data. We can use `str_extract()` if we want, but it's actually faster to use `separate()`, which is part of the `tidyr` package. 

```{r}
table3 %>%
  separate(col = rate, into = c("cases", "population"), sep = "/", remove = F)
```

I've left the rate column in the original data frame just to make it easy to compare and verify that yes, it worked. 

[The `scan()` function in SAS can be used similarly](https://communities.sas.com/t5/SAS-Procedures/Splitting-a-delimited-column-into-multiple-columns/td-p/351130), though it doesn't have quite the simplicity and convenience of `separate`.
```{sashtml sas-table3-scan}
data table3;
length country $12 rate $20;
input country $ year rate $;
datalines;
Afghanistan  1999 745/19987071     
Afghanistan  2000 2666/20595360    
Brazil       1999 37737/172006362  
Brazil       2000 80488/174504898  
China        1999 212258/1272915272
China        2000 213766/1280428583
;
data table3split;
set table3;
length var1-var2 $10.;
array var(2) $;
do i = 1 to dim(var);
  var[i]=scan(rate, i, '/', 'M');
end;
count = var1;
population = var2;
run;
```

`separate()` has a complement, `unite()`, which is useful for handling situations like in table5:
```{r}
table5 %>%
  unite(col = "year", century:year, sep = '') %>%
  separate(col = rate, into = c("cases", "population"), sep = "/")
```

Of course, it's much easier just to do a similar two-step operation (we have to convert to numeric variables to do math)
```{r}
table5 %>%
  mutate(year = as.numeric(century)*100 + as.numeric(year)) %>% 
  select(-century)
```

(Handy shortcut functions in `dplyr` don't completely remove the need to think).

Similarly, it is possible to do this operation in SAS as well (by string concatenation or using the numeric approach), as shown below:

```{sashtml sas-table5-concatenate}
/* read in the data */
DATA table5;
LENGTH country $12 century year rate $20;
INPUT country $ century year rate $;
DATALINES;
Afghanistan 19      99   745/19987071      
Afghanistan 20      00   2666/20595360     
Brazil      19      99   37737/172006362   
Brazil      20      00   80488/174504898   
China       19      99   212258/1272915272 
China       20      00   213766/1280428583 
;

/* Format the data */
DATA table5split;
  SET table5;
  LENGTH v1-v2 $10. yyc $3. centc $3. yyyyc $4.;
  ARRAY v(2) $;
  DO i = 1 TO dim(v);
    v[i]=scan(rate, i, '/', 'M');
  END;
  count = v1;
  population = v2;
  /* Numeric version */
  year = century*100 + year;
  /* Character version */
  yyc = PUT(year, 2.); /* convert to character */
  centc = PUT(century, 2.); /* convert to character */
  yyyyc = CATT('', centc, yearc); /* catt is truncate, then concatenate */
RUN;

/* Print the data */
PROC PRINT DATA=table5split;
  VAR country year yyyyc count population rate centc century yyc;
RUN;
```


## Pivot operations

### Wider

### Longer

## Summaries

## Separating one variable into many
